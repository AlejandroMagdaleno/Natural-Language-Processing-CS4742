{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Project.ipynb",
      "provenance": [],
      "mount_file_id": "1nMqXsm82fzmr25ie6mYMOmwEh0Q3fVC8",
      "authorship_tag": "ABX9TyPXQlhIBq0LwJEXMuqYn/Pr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlejandroMagdaleno/Natural-Language-Processing-CS4742/blob/main/NLP_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Loi2b_Wzsz1P",
        "outputId": "e7a0738a-8a84-4d6f-db65-0457c6ca4e6b"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n",
        "\n",
        "\n",
        "data_dir = '/content/drive/MyDrive/NEWS'\n",
        "\n",
        "train_dir = os.path.join(data_dir, 'train')\n",
        "\n",
        "batch_size = 32\n",
        "seed = 42\n",
        "\n",
        "\n",
        "raw_train_dataset = tf.keras.preprocessing.text_dataset_from_directory('/content/drive/MyDrive/NEWS/train', \n",
        "                                                                       batch_size = batch_size,\n",
        "                                                                       seed=seed)\n",
        "\n",
        "\n",
        "raw_test_dataset = tf.keras.preprocessing.text_dataset_from_directory('/content/drive/MyDrive/NEWS/test',\n",
        "                                                                      batch_size=batch_size)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 88 files belonging to 2 classes.\n",
            "Found 25 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csEEd3JxsYNV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb84aa43-0eba-405f-ea89-b57d04b76bc3"
      },
      "source": [
        "max_features = 10000\n",
        "sequence_length = 250\n",
        "\n",
        "vectorize_layer = layers.TextVectorization(max_tokens = max_features,\n",
        "                                           output_mode = 'int',\n",
        "                                           output_sequence_length = sequence_length)\n",
        "\n",
        "train_text = raw_train_dataset.map(lambda x, y: x)\n",
        "vectorize_layer.adapt(train_text) ## Calling adapt to create a vocabulary and frequency from values in the data. This is Tensorflows implementation of embedding"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7f5d98028e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdDfsm_tyNuG"
      },
      "source": [
        "def vectorize_text(text, label):\n",
        "  text = tf.expand_dims(text, -1)\n",
        "  return vectorize_layer(text), label\n",
        "  \n",
        "train_data = raw_train_dataset.map(vectorize_text)\n",
        "test_data = raw_test_dataset.map(vectorize_text)\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE         ## OPTIONAL, we are prefetching the next data while we are training on current step x to speed process. \n",
        "                                    ## Autotune will set the number of elements to prefetch which should ideally be the number of batches consumed. In our case 32\n",
        "train_data = train_data.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "test_data = test_data.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EaIb_Aoyjfc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b093927-c4f3-4a19-d30f-89dc269d2139"
      },
      "source": [
        "embedding_dim = 16 ##Embedding layer dimsensions for vocabulary\n",
        "\n",
        "## Customize neural network for complexity \n",
        "model = tf.keras.Sequential([\n",
        "  layers.Embedding(max_features + 1, embedding_dim),\n",
        "  layers.Dropout(0.2),   \n",
        "  layers.Dense(5),\n",
        "  layers.GlobalAveragePooling1D(),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.Dense(5),\n",
        "  layers.Dense(1)]) ## Has to stay as one due to binary classification. Only need one neuron for final layer\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, None, 16)          160016    \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, None, 16)          0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, None, 5)           85        \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_3 ( (None, 5)                 0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 5)                 0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 5)                 30        \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 6         \n",
            "=================================================================\n",
            "Total params: 160,137\n",
            "Trainable params: 160,137\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBPpcmIzy3ol"
      },
      "source": [
        "model.compile(loss=losses.BinaryCrossentropy(from_logits=True),optimizer='adam',metrics=tf.metrics.BinaryAccuracy(threshold=0.0))"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOJ8xwVyzGEN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe987489-7939-4073-fb7f-a72ed54eb5a8"
      },
      "source": [
        "epochs = 50\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    epochs=epochs)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "3/3 [==============================] - 1s 11ms/step - loss: 0.6923 - binary_accuracy: 0.6136\n",
            "Epoch 2/50\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6898 - binary_accuracy: 0.6477\n",
            "Epoch 3/50\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.6871 - binary_accuracy: 0.6477\n",
            "Epoch 4/50\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6853 - binary_accuracy: 0.6023\n",
            "Epoch 5/50\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6829 - binary_accuracy: 0.6136\n",
            "Epoch 6/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.6790 - binary_accuracy: 0.6136\n",
            "Epoch 7/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.6755 - binary_accuracy: 0.6136\n",
            "Epoch 8/50\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.6734 - binary_accuracy: 0.6136\n",
            "Epoch 9/50\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6689 - binary_accuracy: 0.6023\n",
            "Epoch 10/50\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.6653 - binary_accuracy: 0.6250\n",
            "Epoch 11/50\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.6623 - binary_accuracy: 0.6136\n",
            "Epoch 12/50\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6589 - binary_accuracy: 0.6477\n",
            "Epoch 13/50\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6575 - binary_accuracy: 0.6250\n",
            "Epoch 14/50\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.6522 - binary_accuracy: 0.6477\n",
            "Epoch 15/50\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.6485 - binary_accuracy: 0.6250\n",
            "Epoch 16/50\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6420 - binary_accuracy: 0.6136\n",
            "Epoch 17/50\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.6349 - binary_accuracy: 0.6250\n",
            "Epoch 18/50\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.6288 - binary_accuracy: 0.6477\n",
            "Epoch 19/50\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.6312 - binary_accuracy: 0.6250\n",
            "Epoch 20/50\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.6140 - binary_accuracy: 0.6250\n",
            "Epoch 21/50\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.6096 - binary_accuracy: 0.6250\n",
            "Epoch 22/50\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.6044 - binary_accuracy: 0.6364\n",
            "Epoch 23/50\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.5968 - binary_accuracy: 0.6477\n",
            "Epoch 24/50\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.5869 - binary_accuracy: 0.6705\n",
            "Epoch 25/50\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.5796 - binary_accuracy: 0.6477\n",
            "Epoch 26/50\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.5649 - binary_accuracy: 0.6705\n",
            "Epoch 27/50\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.5617 - binary_accuracy: 0.6818\n",
            "Epoch 28/50\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.5525 - binary_accuracy: 0.6591\n",
            "Epoch 29/50\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.5471 - binary_accuracy: 0.6477\n",
            "Epoch 30/50\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.5336 - binary_accuracy: 0.6705\n",
            "Epoch 31/50\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.5244 - binary_accuracy: 0.6705\n",
            "Epoch 32/50\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.5148 - binary_accuracy: 0.6932\n",
            "Epoch 33/50\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.5035 - binary_accuracy: 0.6705\n",
            "Epoch 34/50\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.4904 - binary_accuracy: 0.7045\n",
            "Epoch 35/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.4790 - binary_accuracy: 0.7273\n",
            "Epoch 36/50\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.4509 - binary_accuracy: 0.7614\n",
            "Epoch 37/50\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.4587 - binary_accuracy: 0.7955\n",
            "Epoch 38/50\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.4473 - binary_accuracy: 0.8750\n",
            "Epoch 39/50\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.4110 - binary_accuracy: 0.8409\n",
            "Epoch 40/50\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.4193 - binary_accuracy: 0.8977\n",
            "Epoch 41/50\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.4125 - binary_accuracy: 0.9318\n",
            "Epoch 42/50\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.3810 - binary_accuracy: 0.9318\n",
            "Epoch 43/50\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.3616 - binary_accuracy: 0.9659\n",
            "Epoch 44/50\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.3503 - binary_accuracy: 0.9659\n",
            "Epoch 45/50\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.3503 - binary_accuracy: 0.9773\n",
            "Epoch 46/50\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.3367 - binary_accuracy: 0.9659\n",
            "Epoch 47/50\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.3209 - binary_accuracy: 0.9773\n",
            "Epoch 48/50\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.2851 - binary_accuracy: 0.9773\n",
            "Epoch 49/50\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.3030 - binary_accuracy: 0.9773\n",
            "Epoch 50/50\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.2839 - binary_accuracy: 0.9659\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujL_-Z8TzWdL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "beadeab7-ce75-4ceb-a98c-1305b10222db"
      },
      "source": [
        "loss, accuracy = model.evaluate(test_data)\n",
        "print(\"Loss: \", loss)\n",
        "print(\"Accuracy: \", accuracy)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 170ms/step - loss: 0.5813 - binary_accuracy: 0.7200\n",
            "Loss:  0.5813011527061462\n",
            "Accuracy:  0.7200000286102295\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-19y5Jo0_3z"
      },
      "source": [
        ""
      ],
      "execution_count": 29,
      "outputs": []
    }
  ]
}